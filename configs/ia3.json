{
    "lora_scaling_rank": 1,
    "lora_rank": 0,
    "lora_init_scale": 0.0,
    "lora_modules": ".*SelfAttention|.*EncDecAttention|.*DenseReluDense",
    "lora_layers": "k|v|wi_1.*",
    "trainable_param_names": ".*lora_b.*",
    "model_modifier": "lora",
    "lr": 3e-3,
    "num_steps": 3000,
    "dataset": "custom",
    "custom_dataset_dir": "src/templates/adherence",
    "few_shot": false,
    "unlikely_loss": 1,
    "length_norm": 1,
    "mc_loss": 1,
    "batch_size": 4,
    "grad_accum_factor": 2,
    "save_model": true,
    "compute_strategy": "deepspeed_stage_3"
}